{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(path):\n",
    "\n",
    "    df_avc = pd.read_csv(path)\n",
    "    df_avc.drop('Unnamed: 0',1,inplace=True)\n",
    "    \n",
    "    df2 = df_avc[['id', 'gender', 'age', 'hypertension', 'heart_disease',\n",
    "       'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level',\n",
    "       'bmi', 'smoking_status', 'stroke']]\n",
    "    df2 = df_avc\n",
    "    df_avc.columns = ['Id','Genre','Age', 'Hypertension', 'Maladie_cardiaque', 'Deja_marie', 'Type_job', 'Zone_residence', 'Glycemie', 'IMC', 'Fumeur', 'AVC']\n",
    "\n",
    "    #Remplacement des valeurs en chaine de caractères en int\n",
    "\n",
    "    #Homme = 0, Femme = 1, Autre = 2\n",
    "    df_avc.Genre = df_avc.Genre.replace('Male', 0)\n",
    "    df_avc.Genre = df_avc.Genre.replace('Female', 1)\n",
    "    df_avc.Genre = df_avc.Genre.replace('Other', 2)\n",
    "\n",
    "    #Déjà marié : 0 => non; 1=> oui\n",
    "    df_avc.Deja_marie = df_avc.Deja_marie.replace('No', 0)\n",
    "    df_avc.Deja_marie = df_avc.Deja_marie.replace('Yes', 1)\n",
    "\n",
    "    #Type de travail : Secteur privé (0), Secteur public (1),\n",
    "    # Auto-entrepreneur (2), enfant (3), jamais travaillé (4)\n",
    "    df_avc.Type_job = df_avc.Type_job.replace('Private', 0)\n",
    "    df_avc.Type_job = df_avc.Type_job.replace('Govt_job', 1)\n",
    "    df_avc.Type_job = df_avc.Type_job.replace('Self-employed', 2)\n",
    "    df_avc.Type_job = df_avc.Type_job.replace('children', 3)\n",
    "    df_avc.Type_job = df_avc.Type_job.replace('Never_worked', 4)\n",
    "\n",
    "    #Zone résidentielle : Urbain (0), Rural (2)\n",
    "    df_avc.Zone_residence = df_avc.Zone_residence.replace('Urban', 0)\n",
    "    df_avc.Zone_residence = df_avc.Zone_residence.replace('Rural', 1)\n",
    "\n",
    "    #Fumeur : Jamais fumé (0), Ancien fumeur (1), Fumeur (2), inconnu (3)\n",
    "    df_avc.Fumeur = df_avc.Fumeur.replace('never smoked', 0)\n",
    "    df_avc.Fumeur = df_avc.Fumeur.replace('formerly smoked', 1)\n",
    "    df_avc.Fumeur = df_avc.Fumeur.replace('smokes', 2)\n",
    "    df_avc.Fumeur = df_avc.Fumeur.replace('Unknown', 3)\n",
    "    \n",
    "    #remplacement des nan par la moyenne de la colonne\n",
    "    #df_avc['IMC'].fillna((df_avc['IMC'].mean()), inplace=True)\n",
    "    \n",
    "    # OU suppression des nan\n",
    "    df_avc = df_avc.dropna()\n",
    "    \n",
    "    #sépération Train/Test\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(df_avc[['Genre', 'Age', 'Hypertension', 'Maladie_cardiaque', 'Deja_marie', 'Type_job', 'Zone_residence', 'Glycemie', 'IMC', 'Fumeur']], df_avc['AVC'], test_size=0.20, random_state=42)\n",
    "    #print(df_avc)\n",
    "    #print(Xtrain)\n",
    "    #print(Ytrain)\n",
    "    #print(Xtest)\n",
    "    #print(Ytest)\n",
    "    return df_avc, Xtrain, Xtest, Ytrain, Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Id  Genre   Age  Hypertension  Maladie_cardiaque  Deja_marie  \\\n",
      "0      9046      0  67.0             0                  1           1   \n",
      "2     31112      0  80.0             0                  1           1   \n",
      "3     60182      1  49.0             0                  0           1   \n",
      "4      1665      1  79.0             1                  0           1   \n",
      "5     56669      0  81.0             0                  0           1   \n",
      "6     53882      0  74.0             1                  1           1   \n",
      "7     10434      1  69.0             0                  0           0   \n",
      "9     60491      1  78.0             0                  0           1   \n",
      "10    12109      1  81.0             1                  0           1   \n",
      "11    12095      1  61.0             0                  1           1   \n",
      "12    12175      1  54.0             0                  0           1   \n",
      "14     5317      1  79.0             0                  1           1   \n",
      "15    58202      1  50.0             1                  0           1   \n",
      "16    56112      0  64.0             0                  1           1   \n",
      "17    34120      0  75.0             1                  0           1   \n",
      "18    27458      1  60.0             0                  0           0   \n",
      "20    70630      1  71.0             0                  0           1   \n",
      "21    13861      1  52.0             1                  0           1   \n",
      "22    68794      1  79.0             0                  0           1   \n",
      "23    64778      0  82.0             0                  1           1   \n",
      "24     4219      0  71.0             0                  0           1   \n",
      "25    70822      0  80.0             0                  0           1   \n",
      "26    38047      1  65.0             0                  0           1   \n",
      "28    54827      0  69.0             0                  1           1   \n",
      "30    43717      0  57.0             1                  0           1   \n",
      "31    33879      0  42.0             0                  0           1   \n",
      "32    39373      1  82.0             1                  0           1   \n",
      "33    54401      0  80.0             0                  1           1   \n",
      "34    14248      0  48.0             0                  0           0   \n",
      "35      712      1  82.0             1                  1           0   \n",
      "...     ...    ...   ...           ...                ...         ...   \n",
      "6072      0      0  66.0             0                  0           1   \n",
      "6073      0      0  66.0             0                  0           1   \n",
      "6074      0      0  57.0             0                  0           1   \n",
      "6075      0      0  57.0             0                  0           1   \n",
      "6076      0      0  57.0             0                  0           1   \n",
      "6077      0      0  57.0             0                  0           1   \n",
      "6078      0      0  68.0             0                  0           1   \n",
      "6079      0      0  68.0             0                  0           1   \n",
      "6080      0      0  68.0             0                  0           1   \n",
      "6081      0      0  68.0             0                  0           1   \n",
      "6082      0      1  68.0             1                  1           1   \n",
      "6083      0      1  68.0             1                  1           1   \n",
      "6084      0      1  68.0             1                  1           1   \n",
      "6085      0      1  68.0             1                  1           1   \n",
      "6086      0      0  57.0             0                  0           1   \n",
      "6087      0      0  57.0             0                  0           1   \n",
      "6088      0      0  57.0             0                  0           1   \n",
      "6089      0      0  57.0             0                  0           1   \n",
      "6090      0      1  14.0             0                  0           0   \n",
      "6091      0      1  14.0             0                  0           0   \n",
      "6092      0      1  14.0             0                  0           0   \n",
      "6093      0      1  14.0             0                  0           0   \n",
      "6094      0      1  75.0             0                  0           1   \n",
      "6095      0      1  75.0             0                  0           1   \n",
      "6096      0      1  75.0             0                  0           1   \n",
      "6097      0      1  75.0             0                  0           1   \n",
      "6102      0      1  78.0             0                  0           1   \n",
      "6103      0      1  78.0             0                  0           1   \n",
      "6104      0      1  78.0             0                  0           1   \n",
      "6105      0      1  78.0             0                  0           1   \n",
      "\n",
      "      Type_job  Zone_residence  Glycemie   IMC  Fumeur  AVC  \n",
      "0            0               0    228.69  36.6       1    1  \n",
      "2            0               1    105.92  32.5       0    1  \n",
      "3            0               0    171.23  34.4       2    1  \n",
      "4            2               1    174.12  24.0       0    1  \n",
      "5            0               0    186.21  29.0       1    1  \n",
      "6            0               1     70.09  27.4       0    1  \n",
      "7            0               0     94.39  22.8       0    1  \n",
      "9            0               0     58.57  24.2       3    1  \n",
      "10           0               1     80.43  29.7       0    1  \n",
      "11           1               1    120.46  36.8       2    1  \n",
      "12           0               0    104.51  27.3       2    1  \n",
      "14           0               0    214.09  28.2       0    1  \n",
      "15           2               1    167.41  30.9       0    1  \n",
      "16           0               0    191.61  37.5       2    1  \n",
      "17           0               0    221.29  25.8       2    1  \n",
      "18           0               0     89.22  37.8       0    1  \n",
      "20           1               1    193.94  22.4       2    1  \n",
      "21           2               0    233.29  48.9       0    1  \n",
      "22           2               0    228.70  26.6       0    1  \n",
      "23           0               1    208.30  32.5       3    1  \n",
      "24           0               0    102.87  27.2       1    1  \n",
      "25           2               1    104.12  23.5       0    1  \n",
      "26           0               1    100.98  28.2       1    1  \n",
      "28           2               0    195.23  28.3       2    1  \n",
      "30           0               0    212.08  44.2       2    1  \n",
      "31           0               1     83.41  25.4       3    1  \n",
      "32           2               0    196.92  22.2       0    1  \n",
      "33           2               0    252.72  30.5       1    1  \n",
      "34           1               0     84.20  29.7       0    1  \n",
      "35           0               1     84.03  26.5       1    1  \n",
      "...        ...             ...       ...   ...     ...  ...  \n",
      "6072         0               1     96.46  24.2       1    1  \n",
      "6073         0               1    116.46  25.2       1    1  \n",
      "6074         0               1    202.28  35.5       1    1  \n",
      "6075         0               1    207.28  36.5       1    1  \n",
      "6076         0               1    217.28  37.5       1    1  \n",
      "6077         0               1    237.28  38.5       1    1  \n",
      "6078         0               1    238.94  43.4       0    1  \n",
      "6079         0               1    243.94  44.4       0    1  \n",
      "6080         0               1    253.94  45.4       0    1  \n",
      "6081         0               1    273.94  46.4       0    1  \n",
      "6082         0               0    252.51  41.5       1    1  \n",
      "6083         0               0    257.51  42.5       1    1  \n",
      "6084         0               0    267.51  43.5       1    1  \n",
      "6085         0               0    287.51  44.5       1    1  \n",
      "6086         0               1     89.96  37.7       3    1  \n",
      "6087         0               1     94.96  38.7       3    1  \n",
      "6088         0               1    104.96  39.7       3    1  \n",
      "6089         0               1    124.96  40.7       3    1  \n",
      "6090         3               1     62.93  31.9       3    1  \n",
      "6091         3               1     67.93  32.9       3    1  \n",
      "6092         3               1     77.93  33.9       3    1  \n",
      "6093         3               1     97.93  34.9       3    1  \n",
      "6094         2               1     83.80  30.3       1    1  \n",
      "6095         2               1     88.80  31.3       1    1  \n",
      "6096         2               1     98.80  32.3       1    1  \n",
      "6097         2               1    118.80  33.3       1    1  \n",
      "6102         0               1     83.81  20.6       3    1  \n",
      "6103         0               1     88.81  21.6       3    1  \n",
      "6104         0               1     98.81  22.6       3    1  \n",
      "6105         0               1    118.81  23.6       3    1  \n",
      "\n",
      "[5745 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "df_avc, Xtrain, Xtest, Ytrain, Ytest=processing(\"healthcare-dataset-stroke-data-1.csv\")\n",
    "print(df_avc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Age</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Maladie_cardiaque</th>\n",
       "      <th>Deja_marie</th>\n",
       "      <th>Type_job</th>\n",
       "      <th>Zone_residence</th>\n",
       "      <th>Glycemie</th>\n",
       "      <th>IMC</th>\n",
       "      <th>Fumeur</th>\n",
       "      <th>AVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>-0.205149</td>\n",
       "      <td>-0.117431</td>\n",
       "      <td>-0.106819</td>\n",
       "      <td>-0.087550</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>-0.182486</td>\n",
       "      <td>-0.100681</td>\n",
       "      <td>0.041227</td>\n",
       "      <td>-0.486952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genre</th>\n",
       "      <td>0.002004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>-0.008063</td>\n",
       "      <td>-0.101059</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>-0.046630</td>\n",
       "      <td>-0.004265</td>\n",
       "      <td>-0.071353</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>-0.090930</td>\n",
       "      <td>-0.013404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.205149</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.293753</td>\n",
       "      <td>0.276473</td>\n",
       "      <td>0.653432</td>\n",
       "      <td>-0.317046</td>\n",
       "      <td>-0.014303</td>\n",
       "      <td>0.312607</td>\n",
       "      <td>0.331293</td>\n",
       "      <td>-0.310227</td>\n",
       "      <td>0.433374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypertension</th>\n",
       "      <td>-0.117431</td>\n",
       "      <td>-0.008063</td>\n",
       "      <td>0.293753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.112152</td>\n",
       "      <td>0.149050</td>\n",
       "      <td>-0.026951</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.219656</td>\n",
       "      <td>0.174204</td>\n",
       "      <td>-0.143549</td>\n",
       "      <td>0.241794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maladie_cardiaque</th>\n",
       "      <td>-0.106819</td>\n",
       "      <td>-0.101059</td>\n",
       "      <td>0.276473</td>\n",
       "      <td>0.112152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120624</td>\n",
       "      <td>-0.055798</td>\n",
       "      <td>-0.001019</td>\n",
       "      <td>0.230403</td>\n",
       "      <td>0.070283</td>\n",
       "      <td>-0.024985</td>\n",
       "      <td>0.223841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deja_marie</th>\n",
       "      <td>-0.087550</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>0.653432</td>\n",
       "      <td>0.149050</td>\n",
       "      <td>0.120624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333817</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>0.195779</td>\n",
       "      <td>0.337835</td>\n",
       "      <td>-0.237122</td>\n",
       "      <td>0.206200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type_job</th>\n",
       "      <td>0.015000</td>\n",
       "      <td>-0.046630</td>\n",
       "      <td>-0.317046</td>\n",
       "      <td>-0.026951</td>\n",
       "      <td>-0.055798</td>\n",
       "      <td>-0.333817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010847</td>\n",
       "      <td>-0.074878</td>\n",
       "      <td>-0.325414</td>\n",
       "      <td>0.262777</td>\n",
       "      <td>-0.078725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zone_residence</th>\n",
       "      <td>0.001817</td>\n",
       "      <td>-0.004265</td>\n",
       "      <td>-0.014303</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.001019</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>-0.010847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>-0.008873</td>\n",
       "      <td>-0.010039</td>\n",
       "      <td>-0.011525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glycemie</th>\n",
       "      <td>-0.182486</td>\n",
       "      <td>-0.071353</td>\n",
       "      <td>0.312607</td>\n",
       "      <td>0.219656</td>\n",
       "      <td>0.230403</td>\n",
       "      <td>0.195779</td>\n",
       "      <td>-0.074878</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.248201</td>\n",
       "      <td>-0.098859</td>\n",
       "      <td>0.347159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMC</th>\n",
       "      <td>-0.100681</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>0.331293</td>\n",
       "      <td>0.174204</td>\n",
       "      <td>0.070283</td>\n",
       "      <td>0.337835</td>\n",
       "      <td>-0.325414</td>\n",
       "      <td>-0.008873</td>\n",
       "      <td>0.248201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.207346</td>\n",
       "      <td>0.180561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fumeur</th>\n",
       "      <td>0.041227</td>\n",
       "      <td>-0.090930</td>\n",
       "      <td>-0.310227</td>\n",
       "      <td>-0.143549</td>\n",
       "      <td>-0.024985</td>\n",
       "      <td>-0.237122</td>\n",
       "      <td>0.262777</td>\n",
       "      <td>-0.010039</td>\n",
       "      <td>-0.098859</td>\n",
       "      <td>-0.207346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.102232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVC</th>\n",
       "      <td>-0.486952</td>\n",
       "      <td>-0.013404</td>\n",
       "      <td>0.433374</td>\n",
       "      <td>0.241794</td>\n",
       "      <td>0.223841</td>\n",
       "      <td>0.206200</td>\n",
       "      <td>-0.078725</td>\n",
       "      <td>-0.011525</td>\n",
       "      <td>0.347159</td>\n",
       "      <td>0.180561</td>\n",
       "      <td>-0.102232</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Id     Genre       Age  Hypertension  \\\n",
       "Id                 1.000000  0.002004 -0.205149     -0.117431   \n",
       "Genre              0.002004  1.000000  0.016944     -0.008063   \n",
       "Age               -0.205149  0.016944  1.000000      0.293753   \n",
       "Hypertension      -0.117431 -0.008063  0.293753      1.000000   \n",
       "Maladie_cardiaque -0.106819 -0.101059  0.276473      0.112152   \n",
       "Deja_marie        -0.087550  0.020528  0.653432      0.149050   \n",
       "Type_job           0.015000 -0.046630 -0.317046     -0.026951   \n",
       "Zone_residence     0.001817 -0.004265 -0.014303     -0.000070   \n",
       "Glycemie          -0.182486 -0.071353  0.312607      0.219656   \n",
       "IMC               -0.100681  0.014403  0.331293      0.174204   \n",
       "Fumeur             0.041227 -0.090930 -0.310227     -0.143549   \n",
       "AVC               -0.486952 -0.013404  0.433374      0.241794   \n",
       "\n",
       "                   Maladie_cardiaque  Deja_marie  Type_job  Zone_residence  \\\n",
       "Id                         -0.106819   -0.087550  0.015000        0.001817   \n",
       "Genre                      -0.101059    0.020528 -0.046630       -0.004265   \n",
       "Age                         0.276473    0.653432 -0.317046       -0.014303   \n",
       "Hypertension                0.112152    0.149050 -0.026951       -0.000070   \n",
       "Maladie_cardiaque           1.000000    0.120624 -0.055798       -0.001019   \n",
       "Deja_marie                  0.120624    1.000000 -0.333817        0.005832   \n",
       "Type_job                   -0.055798   -0.333817  1.000000       -0.010847   \n",
       "Zone_residence             -0.001019    0.005832 -0.010847        1.000000   \n",
       "Glycemie                    0.230403    0.195779 -0.074878       -0.003313   \n",
       "IMC                         0.070283    0.337835 -0.325414       -0.008873   \n",
       "Fumeur                     -0.024985   -0.237122  0.262777       -0.010039   \n",
       "AVC                         0.223841    0.206200 -0.078725       -0.011525   \n",
       "\n",
       "                   Glycemie       IMC    Fumeur       AVC  \n",
       "Id                -0.182486 -0.100681  0.041227 -0.486952  \n",
       "Genre             -0.071353  0.014403 -0.090930 -0.013404  \n",
       "Age                0.312607  0.331293 -0.310227  0.433374  \n",
       "Hypertension       0.219656  0.174204 -0.143549  0.241794  \n",
       "Maladie_cardiaque  0.230403  0.070283 -0.024985  0.223841  \n",
       "Deja_marie         0.195779  0.337835 -0.237122  0.206200  \n",
       "Type_job          -0.074878 -0.325414  0.262777 -0.078725  \n",
       "Zone_residence    -0.003313 -0.008873 -0.010039 -0.011525  \n",
       "Glycemie           1.000000  0.248201 -0.098859  0.347159  \n",
       "IMC                0.248201  1.000000 -0.207346  0.180561  \n",
       "Fumeur            -0.098859 -0.207346  1.000000 -0.102232  \n",
       "AVC                0.347159  0.180561 -0.102232  1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avc.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "#fonction trouvé sur sklearn pour afficher le learning rate\n",
    "print(__doc__)\n",
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 10)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : estimator instance\n",
    "        An estimator instance implementing `fit` and `predict` methods which\n",
    "        will be cloned for each validation.\n",
    "\n",
    "    title : str\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like of shape (n_samples, n_features)\n",
    "        Training vector, where ``n_samples`` is the number of samples and\n",
    "        ``n_features`` is the number of features.\n",
    "\n",
    "    y : array-like of shape (n_samples) or (n_samples, n_features)\n",
    "        Target relative to ``X`` for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array-like of shape (3,), default=None\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple of shape (2,), default=None\n",
    "        Defines minimum and maximum y-values plotted, e.g. (ymin, ymax).\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, default=None\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, default=None\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like of shape (n_ticks,)\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the ``dtype`` is float, it is regarded\n",
    "        as a fraction of the maximum size of the training set (that is\n",
    "        determined by the selected validation method), i.e. it has to be within\n",
    "        (0, 1]. Otherwise it is interpreted as absolute sizes of the training\n",
    "        sets. Note that for classification the number of samples usually have\n",
    "        to be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choix du modele\n",
    "#### Nos données sont labelisés donc on va tester des algos d'apprentissage supervisé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on commence par le perceptron, pour tester l'algo le plus \"basique\" meme si on sait que ca ne sera pas le meilleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8224543080939948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "perceptron=Perceptron(n_jobs=-1)\n",
    "\n",
    "parameters = {'penalty':('l2','l1','elasticnet',None),\n",
    "              'max_iter':(100,500,1000,2000,5000),\n",
    "              'tol':(1e-3,1e-4,1e-5),\n",
    "              'eta0':(1,0.1,0.01)\n",
    "             }\n",
    "\n",
    "clf = GridSearchCV(perceptron, parameters,refit=True)\n",
    "\n",
    "clf.fit(Xtrain, Ytrain)\n",
    "print(clf.score(Xtest,Ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=0.1,\n",
      "      fit_intercept=True, max_iter=100, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=-1, penalty='l2', random_state=0, shuffle=True, tol=0.001,\n",
      "      validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "learning_curve() got an unexpected keyword argument 'return_times'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-77674b5597ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m plot_learning_curve(clf.best_estimator_, title, Xtrain, Ytrain, ylim=(0.1, 1.01),\n\u001b[0;32m----> 6\u001b[0;31m                     cv=None, n_jobs=4)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5c2ec223d7bf>\u001b[0m in \u001b[0;36mplot_learning_curve\u001b[0;34m(estimator, title, X, y, axes, ylim, cv, n_jobs, train_sizes)\u001b[0m\n\u001b[1;32m     85\u001b[0m         learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n\u001b[1;32m     86\u001b[0m                        \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                        return_times=True)\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mtrain_scores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mtrain_scores_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: learning_curve() got an unexpected keyword argument 'return_times'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = \"Perceptron\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "print(clf.best_estimator_)\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "plot_learning_curve(clf.best_estimator_, title, Xtrain, Ytrain, ylim=(0.1, 1.01),\n",
    "                    cv=None, n_jobs=4)\n",
    "metrics.plot_roc_curve(clf.best_estimator_, Xtest, Ytest) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70% de reussite et une courbe ROC qui n'est pas si mauvaise pour un premier resultat, testons d autres algo pour faire mieux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on va tester les differents modeles pour Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "parameters1 = {'alpha':(1,0.1,0),\n",
    "              'fit_prior':(True,False)\n",
    "             }\n",
    "\n",
    "parameters2 = {'var_smoothing':(1e-9,1e-8,1e-10)\n",
    "             }\n",
    "\n",
    "\n",
    "MNB=GridSearchCV(MultinomialNB(), parameters1,refit=True)\n",
    "GNB=GridSearchCV(GaussianNB(), parameters2,refit=True)\n",
    "BNB=GridSearchCV(BernoulliNB(), parameters1,refit=True)\n",
    "\n",
    "MNB.fit(Xtrain,Ytrain)\n",
    "GNB.fit(Xtrain,Ytrain)\n",
    "BNB.fit(Xtrain,Ytrain)\n",
    "\n",
    "m=MNB.score(Xtest,Ytest)\n",
    "g=GNB.score(Xtest,Ytest)\n",
    "b=BNB.score(Xtest,Ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7798085291557877\n",
      "0.8102697998259356\n",
      "0.8285465622280244\n"
     ]
    }
   ],
   "source": [
    "print(m)\n",
    "print(g)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "learning_curve() got an unexpected keyword argument 'return_times'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8fc9e251db6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m plot_learning_curve(clf.best_estimator_, title, Xtrain, Ytrain, ylim=(0.1, 1.01),\n\u001b[0;32m----> 6\u001b[0;31m                     cv=cv, n_jobs=4)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"GaussianNB\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5c2ec223d7bf>\u001b[0m in \u001b[0;36mplot_learning_curve\u001b[0;34m(estimator, title, X, y, axes, ylim, cv, n_jobs, train_sizes)\u001b[0m\n\u001b[1;32m     85\u001b[0m         learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n\u001b[1;32m     86\u001b[0m                        \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                        return_times=True)\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mtrain_scores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mtrain_scores_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: learning_curve() got an unexpected keyword argument 'return_times'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = \"MultinomialNB\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "print(MNB.best_estimator_)\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "plot_learning_curve(clf.best_estimator_, title, Xtrain, Ytrain, ylim=(0.1, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "title = \"GaussianNB\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "print(GNB.best_estimator_)\n",
    "plot_learning_curve(GNB.best_estimator_, title, Xtrain, Ytrain, ylim=(0.1, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "title = \"BernoulliNB\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "print(BNB.best_estimator_)\n",
    "plot_learning_curve(clf.best_estimator_, title, Xtrain, Ytrain, ylim=(0.1, 1.01),\n",
    "                    cv=cv, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.metrics' has no attribute 'plot_roc_curve'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-734b20b38e20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.metrics' has no attribute 'plot_roc_curve'"
     ]
    }
   ],
   "source": [
    "metrics.plot_roc_curve(MNB.best_estimator_, Xtest, Ytest)\n",
    "metrics.plot_roc_curve(GNB.best_estimator_, Xtest, Ytest) \n",
    "metrics.plot_roc_curve(BNB.best_estimator_, Xtest, Ytest) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les scores sont meilleurs que le perceptron, mais quand on compare les courbes Roc des trois modele il parait beaucoup plus interessant de choisir le modele Gaussien pour Naive Bayes meme avec un taux de reussite legerement plus faible que celui de bernoulli il a une courbe Roc bien meilleur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on teste le MLP\n",
    "##### le perceptron n'etais pas si mauvais donc on va essayer le mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8781549173194082\n"
     ]
    }
   ],
   "source": [
    "#cette case sert juste a ne pas avoir a réexecuter tous le code de la recherche de parametre pour MLP qui est excessivement long\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp=MLPClassifier(activation='tanh', max_iter=2000, tol=1e-05)\n",
    "mlp.fit(Xtrain, Ytrain)\n",
    "print(mlp.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "mlp=MLPClassifier(max_iter=2000)\n",
    "\n",
    "parameters = {'activation':('identity', 'logistic', 'tanh', 'relu'),\n",
    "              'solver':('sgd', 'adam'),\n",
    "              'alpha':(0.0001,0.001,0.00001),\n",
    "              'learning_rate':('constant', 'invscaling', 'adaptive'),\n",
    "              #'power_t':(0.1, 0.5,0.75,1),\n",
    "              #'max_iter':(1000,2000),\n",
    "              'tol':(1e-3, 1e-4, 1e-5),\n",
    "              #'momentum':(0.9, 0.8, 0.7,0.6,0.5,0),\n",
    "              #'beta_1':(0.9, 0.8, 0.7,0.6,0.5),\n",
    "              #'beta_2':(0.999, 0.990, 0.9),\n",
    "              #'epsilon':(1e-8,1e-9,1e-7,1e-10,1e-6)\n",
    "             }\n",
    "\n",
    "MLP = GridSearchCV(mlp, parameters,refit=True)\n",
    "\n",
    "MLP.fit(Xtrain, Ytrain)\n",
    "print(MLP.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MLP.best_estimator_)\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "plot_learning_curve(MLP.best_estimator_, title, Xtrain, Ytrain, ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "metrics.plot_roc_curve(MLP.best_estimator_, Xtest, Ytest) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On teste le KNN\n",
    "##### on va voir si le knn peut former des groupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "parameters = {'n_neighbors':(3,4,5,6,7),\n",
    "              'weights':('uniform', 'distance'),\n",
    "              'algorithm':('auto', 'ball_tree', 'kd_tree', 'brute'),\n",
    "              'leaf_size':(20, 30, 40),\n",
    "              'p':(1, 2,3,)\n",
    "             }\n",
    "\n",
    "neigh = GridSearchCV(KNeighborsClassifier(n_jobs=-1), parameters,refit=True)\n",
    "neigh.fit(Xtrain, Ytrain)\n",
    "n=neigh.score(Xtest,Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"KNN\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "print(neigh.best_estimator_)\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "plot_learning_curve(neigh.best_estimator_, title, Xtrain, Ytrain, ylim=(0.7, 1.01),\n",
    "                    cv=None, n_jobs=4)\n",
    "#MLPClassifier(activation='tanh', learning_rate='adaptive', max_iter=2000)\n",
    "metrics.plot_roc_curve(neigh.best_estimator_, Xtest, Ytest) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86% de reussite avec une bonne courbe ROC, il a un score legerement meilleur que le mlp  avec une courbe roc Similaire.\n",
    "Cependant pour les departager il faudrait plus de donnees pour voir si le training score et le cross validation score peuvent converger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On teste RandomForest\n",
    "##### le dernier algo qui pourrait etre meilleur que les autres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "parameters = {'n_estimators':(100,250,500),\n",
    "              'criterion':('gini', 'entropy')\n",
    "             }\n",
    "\n",
    "rf= GridSearchCV(RandomForestClassifier(n_jobs=-1), parameters,refit=True)\n",
    "\n",
    "rf.fit(Xtrain, Ytrain)\n",
    "rf.score(Xtest,Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"RandomForest\"\n",
    "print(rf.best_estimator_)\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "plot_learning_curve(rf.best_estimator_, title, Xtrain, Ytrain, ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "metrics.plot_roc_curve(rf.best_estimator_, Xtest, Ytest) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "93% de reussite avec une courbe Roc Excellente.On peut meme supposer aux v ude la courbe d apprentissage qu'avec un jeu de donne plus grand on aurait un meilleur score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "On peut voir que random forest est le meilleur avec un score avec 93% donc c'est celui que l'on va garder pour predire les AVC\n",
    "#### On crée la fonction de prediction\n",
    "on met l'algo en parametre pour pouvoir le changer plus facilement si besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(estimator,G:int, A:int, H:int, MC:int, DM:int, TJ:int, ZR:int, Gly:int, imc:int, F:int):\n",
    "    data={'Genre':[G],'Age':[A],'Hypertension':[H],'Maladie_cardiaque':[MC],'Deja_marie':[DM],'Type_job':[TJ],'Zone_residence':[ZR],'Glycemie':[Gly],'IMC':[imc],'Fumeur':[F]}\n",
    "    df = pd.DataFrame(data)\n",
    "    return [estimator.predict(df),estimator.predict_proba(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un exemple de l utilisation de la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction(rf,G=1, A=49, H=0, MC=0, DM=1, TJ=0, ZR=0, Gly=171, imc=36, F=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
